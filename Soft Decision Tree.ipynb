{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320f5ec2",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd37b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3f7dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    for gpu_id in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "        print(f\"GPU {gpu_id}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"No GPUs available on this system.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ccdd1",
   "metadata": {},
   "source": [
    "## Internal Nodes and Tree Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd09a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Internal_Node():\n",
    "    \n",
    "    def __init__(self,depth):\n",
    "        \n",
    "        \n",
    "        self.filter=nn.Linear(28*28,1, bias=True)\n",
    "        \n",
    "        #self.beta=nn.Parameter(torch.randn(1))\n",
    "        \n",
    "        self.leaf=False\n",
    "        \n",
    "        self.depth=depth\n",
    "        self.alpha=None\n",
    "        \n",
    "        \n",
    "    def proceed(self,x):\n",
    "        \n",
    "        #let batch (64,784) go through nn.Linear and get (64,1)\n",
    "        x=self.filter(x)\n",
    "        \n",
    "        #inverse temperature sharpen the direction prob\n",
    "        #x=x*self.beta\n",
    "        \n",
    "        #apply sigmoid to get going right probability (64,1) to (64,1)\n",
    "        right_prob=torch.sigmoid(x)\n",
    "        \n",
    "        \n",
    "        return right_prob\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc87291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf_Node():\n",
    "    def __init__(self,argument):\n",
    "        \n",
    "        \n",
    "        self.num_classes=argument.number_classes\n",
    "        \n",
    "        self.batch_size=argument.batch_size\n",
    "        self.leaf=True\n",
    "        \n",
    "        #initialize the parameter for outputing softmax probability\n",
    "        self.param=torch.randn(1,self.num_classes)\n",
    "        self.param=nn.Parameter(self.param)\n",
    "        \n",
    "    def partial_proceed(self):\n",
    "        \n",
    "        #for testing purpose\n",
    "        distribution=torch.softmax(self.param, dim=1)\n",
    "        \n",
    "        return distribution\n",
    "        \n",
    "    def proceed(self):        \n",
    "        \n",
    "        distribution=torch.softmax(self.param, dim=1)\n",
    "        \n",
    "        #duplicate along the first dimention (1,10) to (64,10)\n",
    "        \n",
    "        distribution=torch.cat([distribution]*self.batch_size,dim=0)\n",
    "        \n",
    "        \n",
    "        return distribution\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7b647",
   "metadata": {},
   "source": [
    "## Construction of Path_dict and Node_dict\n",
    "Path_prob_dict and Node dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3b59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_dict_creation(tree_depth):\n",
    "    path_dict={}\n",
    "    \n",
    "    for i in range(2**(tree_depth-1)):\n",
    "    \n",
    "        #useful for iteratively create Path_Names\n",
    "        path_name=f\"path_{i+1}\"\n",
    "    \n",
    "        path_list=[]\n",
    "    \n",
    "        #initial path\n",
    "        for k in range(tree_depth):\n",
    "            path_list.append((k+1,1))\n",
    "    \n",
    "        #put all node_coordination into a list for counting purpose\n",
    "        all_tuples = [item for sublist in path_dict.values() for item in sublist]\n",
    "    \n",
    "    \n",
    "        #For iterative change the node coordination based on number of occurrence in the path_dict\n",
    "        for i in range(tree_depth):\n",
    "        \n",
    "            #if different depth's node appear certain times, change it, use while to do it iteratively\n",
    "            while all_tuples.count(path_list[-(i+1)])==2**i:\n",
    "            \n",
    "                #continue addition if there is repetitive occurrence\n",
    "                path_list[-(i+1)]=(path_list[-(i+1)][0],path_list[-(i+1)][1]+1)\n",
    "    \n",
    "        path_dict[path_name]=path_list\n",
    "    \n",
    "    \n",
    "    return path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15bff14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path_1': [(1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " 'path_2': [(1, 1), (2, 1), (3, 1), (4, 2)],\n",
       " 'path_3': [(1, 1), (2, 1), (3, 2), (4, 3)],\n",
       " 'path_4': [(1, 1), (2, 1), (3, 2), (4, 4)],\n",
       " 'path_5': [(1, 1), (2, 2), (3, 3), (4, 5)],\n",
       " 'path_6': [(1, 1), (2, 2), (3, 3), (4, 6)],\n",
       " 'path_7': [(1, 1), (2, 2), (3, 4), (4, 7)],\n",
       " 'path_8': [(1, 1), (2, 2), (3, 4), (4, 8)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dict_4=path_dict_creation(tree_depth=4)\n",
    "path_dict_5=path_dict_creation(tree_depth=5)\n",
    "path_dict_6=path_dict_creation(tree_depth=6)\n",
    "\n",
    "path_dict_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0b67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_dict_creation(path_dict):\n",
    "    node_set=set()\n",
    "\n",
    "    node_dict={}\n",
    "    for value in path_dict.values():\n",
    "    \n",
    "        value=tuple(value)\n",
    "    \n",
    "        node_dict[value]=[]\n",
    "    \n",
    "    #iterate through key of node dict(value pf path_dict) (path nodes are going to take)\n",
    "    for key in node_dict.keys():\n",
    "        \n",
    "        #add nodes according to path\n",
    "        for i in range(len(key)):\n",
    "            \n",
    "            #avoid repetitive creation of internal nodes\n",
    "            if key[i] not in node_set:\n",
    "                \n",
    "                #for adding internal nodes\n",
    "                if i <len(key)-1:\n",
    "                    \n",
    "                    #attach a depth for regularization, key[i] is the coordination of the node\n",
    "                    #k[i][0] is the depth (3,1) - depth=3\n",
    "                    \n",
    "                    node=Internal_Node(depth=key[i][0])\n",
    "                    \n",
    "                    node_dict[key].append(node)\n",
    "                    \n",
    "                    #add node's coordination into set to keep a record\n",
    "                    node_set.add(key[i])\n",
    "            \n",
    "            #if already exists\n",
    "            else:\n",
    "                \n",
    "                node_dict[key].append(node_dict[old_key][i])\n",
    "            \n",
    "            if i ==len(key)-1:\n",
    "                \n",
    "                node=Leaf_Node(argu)\n",
    "                node_dict[key].append(node)\n",
    "        \n",
    "        # for sharing node purpose\n",
    "        old_key=key\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        \n",
    "    return node_dict\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48dda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(tree_depth):\n",
    "    \n",
    "    path_dict=path_dict_creation(tree_depth)\n",
    "    \n",
    "    node_dict=node_dict_creation(path_dict)\n",
    "    return node_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec48b6c",
   "metadata": {},
   "source": [
    "## Tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c201da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.number_classes=10\n",
    "        self.epochs=30\n",
    "        self.cuda=True\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batch_size=128\n",
    "        self.lr=0.012\n",
    "        self.momentum=0.9\n",
    "        #you considered the leaves as tree depth as well, remember the difference (+1)\n",
    "        self.tree_depth=9\n",
    "        self.lmbda=0.02\n",
    "        \n",
    "argu=Arguments() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed51597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict=get_dict(argu.tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24bf71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define data transformations to preprocess the images\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Download and load the training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=argu.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Download and load the testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=argu.batch_size, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f47a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class Nt(nn.Module):\n",
    "    def __init__(self,arguments,node_dict):\n",
    "        super(Nt,self).__init__()\n",
    "\n",
    "        self.args=arguments\n",
    "        self.lmbda=self.args.lmbda\n",
    "        \n",
    "        \n",
    "        self.batch_size=self.args.batch_size\n",
    "        \n",
    "        self.epochs=self.args.epochs\n",
    "        self.module_list=nn.ModuleList()\n",
    "        self.param_list=nn.ParameterList()\n",
    "        \n",
    "        \n",
    "        #rewrite once automated\n",
    "        self.node_dict=node_dict\n",
    "        \n",
    "        \n",
    "        self.collect_parameters()\n",
    "        self.loss=nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=self.args.lr, momentum=self.args.momentum)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def collect_parameters(self):\n",
    "        \n",
    "        node_set=set()\n",
    "        for value in self.node_dict.values():\n",
    "            \n",
    "            for i in range(len(value)):\n",
    "                if value[i] not in node_set:\n",
    "                    if value[i].leaf==False:\n",
    "                        self.module_list.append(value[i].filter)\n",
    "                        #self.param_list.append(value[i].beta)\n",
    "                        \n",
    "                        node_set.add(value[i])\n",
    "                    else:\n",
    "                        self.param_list.append(value[i].param)\n",
    "\n",
    "    def predict(self,x):\n",
    "        \n",
    "        output_=0\n",
    "        for key,value in self.node_dict.items():\n",
    "    \n",
    "   \n",
    "            leaf_prob=value[-1].proceed()\n",
    "    \n",
    "    \n",
    "            path_prob=torch.ones(self.batch_size,1)\n",
    "    \n",
    "            #iterate through nodes in the path\n",
    "            for i in range(len(key)-1):\n",
    "        \n",
    "                going_right=value[i].proceed(x)\n",
    "                going_left=1-going_right\n",
    "                \n",
    "                \n",
    "                #For computing alpha\n",
    "                \n",
    "                if self.args.cuda==True:\n",
    "                    path_prob=path_prob.cuda()\n",
    "                    going_right=going_right.cuda()\n",
    "                \n",
    "                \n",
    "                value[i].alpha=torch.sum(path_prob*going_right)/torch.sum(path_prob)\n",
    "                \n",
    "        \n",
    "                #condition for going right\n",
    "                if key[i+1][1]/key[i][1]==2:\n",
    "            \n",
    "                    path_prob=path_prob*going_right\n",
    "            \n",
    "                else:\n",
    "                    \n",
    "                    \n",
    "                    path_prob=path_prob*going_left\n",
    "    \n",
    "            #aggregate prediction\n",
    "            output_+=path_prob*leaf_prob\n",
    "\n",
    "        return output_ \n",
    "    \n",
    "    def train_(self,train_loader,test_loader):\n",
    "        self.train()\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            print(\"Epoch:{}\".format(i+1))\n",
    "            \n",
    "            \n",
    "            total_loss=0\n",
    "            \n",
    "            batch=0\n",
    "            total_samples=0\n",
    "            correct_predictions=0\n",
    "            \n",
    "            #Tracking how loss is progressing\n",
    "            avg_loss=0\n",
    "            avg_regularization=0\n",
    "            \n",
    "            for batch_idx, (data, label) in enumerate(train_loader):\n",
    "                \n",
    "                batch+=1\n",
    "            \n",
    "                if self.args.cuda==True:\n",
    "                    data, label=data.cuda(),label.cuda()\n",
    "                    self.cuda()\n",
    "                    \n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                \n",
    "                \n",
    "               \n",
    "                #change (batch,1,28,28) to (batch, 28*28)\n",
    "                data=data.view(self.batch_size,-1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #forward_pass\n",
    "                output=self.predict(data)\n",
    "               \n",
    "            \n",
    "                #For accuracy purpose\n",
    "                \n",
    "                ##max_value, index of predicted label,     two position output\n",
    "                _, predicted_label = torch.max(output, dim=1, keepdim=True)\n",
    "                \n",
    "                correct_predictions += (predicted_label == label.view_as(predicted_label)).sum().item()\n",
    "               \n",
    "                total_samples += label.size(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                #updating process\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss=self.loss(output,label)\n",
    "                \n",
    "                \n",
    "                # Regularizers\n",
    "                regularization=0\n",
    "                \n",
    "                #iterate through all nodes\n",
    "                for value in node_dict.values():\n",
    "                    \n",
    "                    for k in range(len(value)):\n",
    "                        #only for internal nodes\n",
    "                        if value[k].leaf==False:\n",
    "                            \n",
    "                            regularization-=self.lmbda*2**(-value[k].depth)*0.5*(torch.log(value[k].alpha)+torch.log(1-value[k].alpha))\n",
    "                        \n",
    "                 #Tracking how loss is progressing\n",
    "                avg_loss+=loss\n",
    "                avg_regularization+=regularization\n",
    "                \n",
    "                loss=loss+regularization\n",
    "                \n",
    "                \n",
    "                \n",
    "                loss.backward(retain_graph=True)\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss+=loss.item()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # verbose\n",
    "                if batch%200==0:\n",
    "                    \n",
    "                    print(\"Batch: {}   Loss: {}   Accumulated Accuracy in this epoch:{:.2f}%\"\n",
    "                          .format(batch, total_loss/batch,correct_predictions/total_samples*100))\n",
    "                    \n",
    "                    print(\"\\nLoss_normal: {}  Regularization: {}\".format( avg_loss/batch, avg_regularization/batch ))\n",
    "        \n",
    "            print(\"\\nOne Epoch done, check for overfitting\")\n",
    "            self.test_(test_loader)\n",
    "        \n",
    "                    \n",
    "        return self.node_dict\n",
    "    \n",
    "    \n",
    "    #evaluating on test dataset\n",
    "    def test_(self,test_loader):\n",
    "        self.eval()\n",
    "        \n",
    "        total_samples=0\n",
    "        correct_predictions=0\n",
    "        \n",
    "        \n",
    "        for batch_idx, (data, label) in enumerate(test_loader):\n",
    "            \n",
    "            if self.args.cuda==True:\n",
    "                    data, label=data.cuda(),label.cuda()\n",
    "                    self.cuda() \n",
    "            \n",
    "            data=data.view(self.batch_size,-1)\n",
    "            \n",
    "            #predict\n",
    "            output=self.predict(data)\n",
    "               \n",
    "            \n",
    "            #For accuracy purpose\n",
    "            ##max_value, index of predicted label\n",
    "            _, predicted_label = torch.max(output, dim=1, keepdim=True)\n",
    "                \n",
    "            correct_predictions += (predicted_label == label.view_as(predicted_label)).sum().item()\n",
    "               \n",
    "            total_samples += label.size(0)\n",
    "            \n",
    "        print(\"Testset Accuracy: {:.2f}%\\n\".format(correct_predictions/total_samples*100))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bf1b8",
   "metadata": {},
   "source": [
    "## Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894e0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tre=Nt(argu,node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "e7f3ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Batch: 200   Loss: 5.294553232192993   Accumulated Accuracy in this epoch:94.40%\n",
      "\n",
      "Loss_normal: 1.6316702365875244  Regularization: 3.6628828048706055\n",
      "Batch: 400   Loss: 5.293789571523666   Accumulated Accuracy in this epoch:94.50%\n",
      "\n",
      "Loss_normal: 1.6295607089996338  Regularization: 3.6642282009124756\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.20%\n",
      "\n",
      "Epoch:2\n",
      "Batch: 200   Loss: 5.295295097827911   Accumulated Accuracy in this epoch:94.56%\n",
      "\n",
      "Loss_normal: 1.6276841163635254  Regularization: 3.6676108837127686\n",
      "Batch: 400   Loss: 5.2934327316284175   Accumulated Accuracy in this epoch:94.56%\n",
      "\n",
      "Loss_normal: 1.6282000541687012  Regularization: 3.6652331352233887\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.30%\n",
      "\n",
      "Epoch:3\n",
      "Batch: 200   Loss: 5.293015840053559   Accumulated Accuracy in this epoch:94.64%\n",
      "\n",
      "Loss_normal: 1.6271252632141113  Regularization: 3.6658923625946045\n",
      "Batch: 400   Loss: 5.291593989133835   Accumulated Accuracy in this epoch:94.64%\n",
      "\n",
      "Loss_normal: 1.6259310245513916  Regularization: 3.665663719177246\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.34%\n",
      "\n",
      "Epoch:4\n",
      "Batch: 200   Loss: 5.287115416526794   Accumulated Accuracy in this epoch:94.90%\n",
      "\n",
      "Loss_normal: 1.6233909130096436  Regularization: 3.663724899291992\n",
      "Batch: 400   Loss: 5.28867057800293   Accumulated Accuracy in this epoch:94.57%\n",
      "\n",
      "Loss_normal: 1.6247467994689941  Regularization: 3.6639256477355957\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.33%\n",
      "\n",
      "Epoch:5\n",
      "Batch: 200   Loss: 5.286929047107696   Accumulated Accuracy in this epoch:94.78%\n",
      "\n",
      "Loss_normal: 1.622397541999817  Regularization: 3.6645328998565674\n",
      "Batch: 400   Loss: 5.287039442062378   Accumulated Accuracy in this epoch:94.73%\n",
      "\n",
      "Loss_normal: 1.622698187828064  Regularization: 3.6643431186676025\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.49%\n",
      "\n",
      "Epoch:6\n",
      "Batch: 200   Loss: 5.282954559326172   Accumulated Accuracy in this epoch:94.96%\n",
      "\n",
      "Loss_normal: 1.6204627752304077  Regularization: 3.6624910831451416\n",
      "Batch: 400   Loss: 5.285617654323578   Accumulated Accuracy in this epoch:94.77%\n",
      "\n",
      "Loss_normal: 1.6206492185592651  Regularization: 3.6649699211120605\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.41%\n",
      "\n",
      "Epoch:7\n",
      "Batch: 200   Loss: 5.285204274654388   Accumulated Accuracy in this epoch:94.90%\n",
      "\n",
      "Loss_normal: 1.6195318698883057  Regularization: 3.6656715869903564\n",
      "Batch: 400   Loss: 5.284143397808075   Accumulated Accuracy in this epoch:94.91%\n",
      "\n",
      "Loss_normal: 1.619612693786621  Regularization: 3.664531707763672\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.49%\n",
      "\n",
      "Epoch:8\n",
      "Batch: 200   Loss: 5.280421531200409   Accumulated Accuracy in this epoch:94.86%\n",
      "\n",
      "Loss_normal: 1.6184864044189453  Regularization: 3.661936044692993\n",
      "Batch: 400   Loss: 5.280364470481873   Accumulated Accuracy in this epoch:94.94%\n",
      "\n",
      "Loss_normal: 1.617923378944397  Regularization: 3.662440299987793\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.49%\n",
      "\n",
      "Epoch:9\n",
      "Batch: 200   Loss: 5.283255715370178   Accumulated Accuracy in this epoch:94.95%\n",
      "\n",
      "Loss_normal: 1.6177446842193604  Regularization: 3.665508985519409\n",
      "Batch: 400   Loss: 5.282272610664368   Accumulated Accuracy in this epoch:94.97%\n",
      "\n",
      "Loss_normal: 1.6169016361236572  Regularization: 3.6653683185577393\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.55%\n",
      "\n",
      "Epoch:10\n",
      "Batch: 200   Loss: 5.278858108520508   Accumulated Accuracy in this epoch:94.91%\n",
      "\n",
      "Loss_normal: 1.615120530128479  Regularization: 3.6637368202209473\n",
      "Batch: 400   Loss: 5.279253667593002   Accumulated Accuracy in this epoch:95.00%\n",
      "\n",
      "Loss_normal: 1.6147856712341309  Regularization: 3.66446852684021\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.61%\n",
      "\n",
      "Epoch:11\n",
      "Batch: 200   Loss: 5.2780741429328915   Accumulated Accuracy in this epoch:94.97%\n",
      "\n",
      "Loss_normal: 1.6132558584213257  Regularization: 3.6648166179656982\n",
      "Batch: 400   Loss: 5.276104729175568   Accumulated Accuracy in this epoch:94.99%\n",
      "\n",
      "Loss_normal: 1.6137300729751587  Regularization: 3.66237473487854\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.62%\n",
      "\n",
      "Epoch:12\n",
      "Batch: 200   Loss: 5.275614855289459   Accumulated Accuracy in this epoch:95.07%\n",
      "\n",
      "Loss_normal: 1.6119614839553833  Regularization: 3.6636531352996826\n",
      "Batch: 400   Loss: 5.275044672489166   Accumulated Accuracy in this epoch:95.11%\n",
      "\n",
      "Loss_normal: 1.612138271331787  Regularization: 3.662907361984253\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.65%\n",
      "\n",
      "Epoch:13\n",
      "Batch: 200   Loss: 5.27431800365448   Accumulated Accuracy in this epoch:95.24%\n",
      "\n",
      "Loss_normal: 1.6110502481460571  Regularization: 3.6632678508758545\n",
      "Batch: 400   Loss: 5.2746121072769165   Accumulated Accuracy in this epoch:95.12%\n",
      "\n",
      "Loss_normal: 1.6115130186080933  Regularization: 3.663100004196167\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.59%\n",
      "\n",
      "Epoch:14\n",
      "Batch: 200   Loss: 5.273604657649994   Accumulated Accuracy in this epoch:95.20%\n",
      "\n",
      "Loss_normal: 1.6107929944992065  Regularization: 3.6628124713897705\n",
      "Batch: 400   Loss: 5.273715552091598   Accumulated Accuracy in this epoch:95.15%\n",
      "\n",
      "Loss_normal: 1.6105210781097412  Regularization: 3.663194417953491\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.60%\n",
      "\n",
      "Epoch:15\n",
      "Batch: 200   Loss: 5.272688863277435   Accumulated Accuracy in this epoch:95.25%\n",
      "\n",
      "Loss_normal: 1.608785629272461  Regularization: 3.6639037132263184\n",
      "Batch: 400   Loss: 5.2719970738887785   Accumulated Accuracy in this epoch:95.21%\n",
      "\n",
      "Loss_normal: 1.6085996627807617  Regularization: 3.663397789001465\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.76%\n",
      "\n",
      "Epoch:16\n",
      "Batch: 200   Loss: 5.267057168483734   Accumulated Accuracy in this epoch:95.30%\n",
      "\n",
      "Loss_normal: 1.607897162437439  Regularization: 3.65916109085083\n",
      "Batch: 400   Loss: 5.270816886425019   Accumulated Accuracy in this epoch:95.17%\n",
      "\n",
      "Loss_normal: 1.6080732345581055  Regularization: 3.6627449989318848\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.68%\n",
      "\n",
      "Epoch:17\n",
      "Batch: 200   Loss: 5.26859277009964   Accumulated Accuracy in this epoch:95.34%\n",
      "\n",
      "Loss_normal: 1.6072791814804077  Regularization: 3.66131329536438\n",
      "Batch: 400   Loss: 5.268253446817398   Accumulated Accuracy in this epoch:95.27%\n",
      "\n",
      "Loss_normal: 1.606831669807434  Regularization: 3.661421537399292\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.76%\n",
      "\n",
      "Epoch:18\n",
      "Batch: 200   Loss: 5.267653157711029   Accumulated Accuracy in this epoch:95.20%\n",
      "\n",
      "Loss_normal: 1.6063857078552246  Regularization: 3.6612682342529297\n",
      "Batch: 400   Loss: 5.268453848361969   Accumulated Accuracy in this epoch:95.24%\n",
      "\n",
      "Loss_normal: 1.6062548160552979  Regularization: 3.6621997356414795\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.77%\n",
      "\n",
      "Epoch:19\n",
      "Batch: 200   Loss: 5.269699382781982   Accumulated Accuracy in this epoch:95.33%\n",
      "\n",
      "Loss_normal: 1.604638934135437  Regularization: 3.6650593280792236\n",
      "Batch: 400   Loss: 5.267857319116592   Accumulated Accuracy in this epoch:95.30%\n",
      "\n",
      "Loss_normal: 1.6050509214401245  Regularization: 3.6628053188323975\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.82%\n",
      "\n",
      "Epoch:20\n",
      "Batch: 200   Loss: 5.2647750234603885   Accumulated Accuracy in this epoch:95.33%\n",
      "\n",
      "Loss_normal: 1.6034247875213623  Regularization: 3.661348819732666\n",
      "Batch: 400   Loss: 5.265128061771393   Accumulated Accuracy in this epoch:95.29%\n",
      "\n",
      "Loss_normal: 1.6038641929626465  Regularization: 3.6612637042999268\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.80%\n",
      "\n",
      "Epoch:21\n",
      "Batch: 200   Loss: 5.267343461513519   Accumulated Accuracy in this epoch:95.36%\n",
      "\n",
      "Loss_normal: 1.6027309894561768  Regularization: 3.664612293243408\n",
      "Batch: 400   Loss: 5.2656858694553375   Accumulated Accuracy in this epoch:95.37%\n",
      "\n",
      "Loss_normal: 1.6024938821792603  Regularization: 3.663191795349121\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.82%\n",
      "\n",
      "Epoch:22\n",
      "Batch: 200   Loss: 5.263322360515595   Accumulated Accuracy in this epoch:95.56%\n",
      "\n",
      "Loss_normal: 1.6011070013046265  Regularization: 3.6622157096862793\n",
      "Batch: 400   Loss: 5.26543163895607   Accumulated Accuracy in this epoch:95.43%\n",
      "\n",
      "Loss_normal: 1.6015158891677856  Regularization: 3.6639158725738525\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.85%\n",
      "\n",
      "Epoch:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200   Loss: 5.260742292404175   Accumulated Accuracy in this epoch:95.50%\n",
      "\n",
      "Loss_normal: 1.600421667098999  Regularization: 3.660320997238159\n",
      "Batch: 400   Loss: 5.262895109653473   Accumulated Accuracy in this epoch:95.43%\n",
      "\n",
      "Loss_normal: 1.601212978363037  Regularization: 3.6616814136505127\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.93%\n",
      "\n",
      "Epoch:24\n",
      "Batch: 200   Loss: 5.264065220355987   Accumulated Accuracy in this epoch:95.42%\n",
      "\n",
      "Loss_normal: 1.6015303134918213  Regularization: 3.6625335216522217\n",
      "Batch: 400   Loss: 5.263441658020019   Accumulated Accuracy in this epoch:95.44%\n",
      "\n",
      "Loss_normal: 1.6009736061096191  Regularization: 3.6624667644500732\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.84%\n",
      "\n",
      "Epoch:25\n",
      "Batch: 200   Loss: 5.262025058269501   Accumulated Accuracy in this epoch:95.47%\n",
      "\n",
      "Loss_normal: 1.5994606018066406  Regularization: 3.662564277648926\n",
      "Batch: 400   Loss: 5.262692667245865   Accumulated Accuracy in this epoch:95.46%\n",
      "\n",
      "Loss_normal: 1.6002607345581055  Regularization: 3.662431478500366\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.94%\n",
      "\n",
      "Epoch:26\n",
      "Batch: 200   Loss: 5.260190279483795   Accumulated Accuracy in this epoch:95.57%\n",
      "\n",
      "Loss_normal: 1.5989099740982056  Regularization: 3.6612799167633057\n",
      "Batch: 400   Loss: 5.260728064775467   Accumulated Accuracy in this epoch:95.53%\n",
      "\n",
      "Loss_normal: 1.5989359617233276  Regularization: 3.661792516708374\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.97%\n",
      "\n",
      "Epoch:27\n",
      "Batch: 200   Loss: 5.257072305679321   Accumulated Accuracy in this epoch:95.58%\n",
      "\n",
      "Loss_normal: 1.596652626991272  Regularization: 3.6604180335998535\n",
      "Batch: 400   Loss: 5.259592796564102   Accumulated Accuracy in this epoch:95.52%\n",
      "\n",
      "Loss_normal: 1.5981642007827759  Regularization: 3.661428689956665\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.96%\n",
      "\n",
      "Epoch:28\n",
      "Batch: 200   Loss: 5.261127412319183   Accumulated Accuracy in this epoch:95.63%\n",
      "\n",
      "Loss_normal: 1.59730863571167  Regularization: 3.6638174057006836\n",
      "Batch: 400   Loss: 5.259326798915863   Accumulated Accuracy in this epoch:95.58%\n",
      "\n",
      "Loss_normal: 1.5971823930740356  Regularization: 3.6621410846710205\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.97%\n",
      "\n",
      "Epoch:29\n",
      "Batch: 200   Loss: 5.256226096153259   Accumulated Accuracy in this epoch:95.55%\n",
      "\n",
      "Loss_normal: 1.596055269241333  Regularization: 3.6601710319519043\n",
      "Batch: 400   Loss: 5.256003038883209   Accumulated Accuracy in this epoch:95.60%\n",
      "\n",
      "Loss_normal: 1.5960711240768433  Regularization: 3.659930944442749\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.92%\n",
      "\n",
      "Epoch:30\n",
      "Batch: 200   Loss: 5.258760612010956   Accumulated Accuracy in this epoch:95.48%\n",
      "\n",
      "Loss_normal: 1.5961800813674927  Regularization: 3.662581443786621\n",
      "Batch: 400   Loss: 5.257591420412064   Accumulated Accuracy in this epoch:95.54%\n",
      "\n",
      "Loss_normal: 1.5960992574691772  Regularization: 3.6614930629730225\n",
      "\n",
      "One Epoch done, check for overfitting\n",
      "Testset Accuracy: 94.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dd_ict=tre.train_(train_loader=trainloader,test_loader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca7ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset Accuracy: 10.15%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tre.test_(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb156d8",
   "metadata": {},
   "source": [
    "## Check number of parameters in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451852d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------------------+\n",
      "|       Layer Name       | Number of Parameters |\n",
      "+------------------------+----------------------+\n",
      "|  module_list.0.weight  |         784          |\n",
      "|   module_list.0.bias   |          1           |\n",
      "|  module_list.1.weight  |         784          |\n",
      "|   module_list.1.bias   |          1           |\n",
      "|  module_list.2.weight  |         784          |\n",
      "|   module_list.2.bias   |          1           |\n",
      "|  module_list.3.weight  |         784          |\n",
      "|   module_list.3.bias   |          1           |\n",
      "|  module_list.4.weight  |         784          |\n",
      "|   module_list.4.bias   |          1           |\n",
      "|  module_list.5.weight  |         784          |\n",
      "|   module_list.5.bias   |          1           |\n",
      "|  module_list.6.weight  |         784          |\n",
      "|   module_list.6.bias   |          1           |\n",
      "|  module_list.7.weight  |         784          |\n",
      "|   module_list.7.bias   |          1           |\n",
      "|  module_list.8.weight  |         784          |\n",
      "|   module_list.8.bias   |          1           |\n",
      "|  module_list.9.weight  |         784          |\n",
      "|   module_list.9.bias   |          1           |\n",
      "| module_list.10.weight  |         784          |\n",
      "|  module_list.10.bias   |          1           |\n",
      "| module_list.11.weight  |         784          |\n",
      "|  module_list.11.bias   |          1           |\n",
      "| module_list.12.weight  |         784          |\n",
      "|  module_list.12.bias   |          1           |\n",
      "| module_list.13.weight  |         784          |\n",
      "|  module_list.13.bias   |          1           |\n",
      "| module_list.14.weight  |         784          |\n",
      "|  module_list.14.bias   |          1           |\n",
      "| module_list.15.weight  |         784          |\n",
      "|  module_list.15.bias   |          1           |\n",
      "| module_list.16.weight  |         784          |\n",
      "|  module_list.16.bias   |          1           |\n",
      "| module_list.17.weight  |         784          |\n",
      "|  module_list.17.bias   |          1           |\n",
      "| module_list.18.weight  |         784          |\n",
      "|  module_list.18.bias   |          1           |\n",
      "| module_list.19.weight  |         784          |\n",
      "|  module_list.19.bias   |          1           |\n",
      "| module_list.20.weight  |         784          |\n",
      "|  module_list.20.bias   |          1           |\n",
      "| module_list.21.weight  |         784          |\n",
      "|  module_list.21.bias   |          1           |\n",
      "| module_list.22.weight  |         784          |\n",
      "|  module_list.22.bias   |          1           |\n",
      "| module_list.23.weight  |         784          |\n",
      "|  module_list.23.bias   |          1           |\n",
      "| module_list.24.weight  |         784          |\n",
      "|  module_list.24.bias   |          1           |\n",
      "| module_list.25.weight  |         784          |\n",
      "|  module_list.25.bias   |          1           |\n",
      "| module_list.26.weight  |         784          |\n",
      "|  module_list.26.bias   |          1           |\n",
      "| module_list.27.weight  |         784          |\n",
      "|  module_list.27.bias   |          1           |\n",
      "| module_list.28.weight  |         784          |\n",
      "|  module_list.28.bias   |          1           |\n",
      "| module_list.29.weight  |         784          |\n",
      "|  module_list.29.bias   |          1           |\n",
      "| module_list.30.weight  |         784          |\n",
      "|  module_list.30.bias   |          1           |\n",
      "| module_list.31.weight  |         784          |\n",
      "|  module_list.31.bias   |          1           |\n",
      "| module_list.32.weight  |         784          |\n",
      "|  module_list.32.bias   |          1           |\n",
      "| module_list.33.weight  |         784          |\n",
      "|  module_list.33.bias   |          1           |\n",
      "| module_list.34.weight  |         784          |\n",
      "|  module_list.34.bias   |          1           |\n",
      "| module_list.35.weight  |         784          |\n",
      "|  module_list.35.bias   |          1           |\n",
      "| module_list.36.weight  |         784          |\n",
      "|  module_list.36.bias   |          1           |\n",
      "| module_list.37.weight  |         784          |\n",
      "|  module_list.37.bias   |          1           |\n",
      "| module_list.38.weight  |         784          |\n",
      "|  module_list.38.bias   |          1           |\n",
      "| module_list.39.weight  |         784          |\n",
      "|  module_list.39.bias   |          1           |\n",
      "| module_list.40.weight  |         784          |\n",
      "|  module_list.40.bias   |          1           |\n",
      "| module_list.41.weight  |         784          |\n",
      "|  module_list.41.bias   |          1           |\n",
      "| module_list.42.weight  |         784          |\n",
      "|  module_list.42.bias   |          1           |\n",
      "| module_list.43.weight  |         784          |\n",
      "|  module_list.43.bias   |          1           |\n",
      "| module_list.44.weight  |         784          |\n",
      "|  module_list.44.bias   |          1           |\n",
      "| module_list.45.weight  |         784          |\n",
      "|  module_list.45.bias   |          1           |\n",
      "| module_list.46.weight  |         784          |\n",
      "|  module_list.46.bias   |          1           |\n",
      "| module_list.47.weight  |         784          |\n",
      "|  module_list.47.bias   |          1           |\n",
      "| module_list.48.weight  |         784          |\n",
      "|  module_list.48.bias   |          1           |\n",
      "| module_list.49.weight  |         784          |\n",
      "|  module_list.49.bias   |          1           |\n",
      "| module_list.50.weight  |         784          |\n",
      "|  module_list.50.bias   |          1           |\n",
      "| module_list.51.weight  |         784          |\n",
      "|  module_list.51.bias   |          1           |\n",
      "| module_list.52.weight  |         784          |\n",
      "|  module_list.52.bias   |          1           |\n",
      "| module_list.53.weight  |         784          |\n",
      "|  module_list.53.bias   |          1           |\n",
      "| module_list.54.weight  |         784          |\n",
      "|  module_list.54.bias   |          1           |\n",
      "| module_list.55.weight  |         784          |\n",
      "|  module_list.55.bias   |          1           |\n",
      "| module_list.56.weight  |         784          |\n",
      "|  module_list.56.bias   |          1           |\n",
      "| module_list.57.weight  |         784          |\n",
      "|  module_list.57.bias   |          1           |\n",
      "| module_list.58.weight  |         784          |\n",
      "|  module_list.58.bias   |          1           |\n",
      "| module_list.59.weight  |         784          |\n",
      "|  module_list.59.bias   |          1           |\n",
      "| module_list.60.weight  |         784          |\n",
      "|  module_list.60.bias   |          1           |\n",
      "| module_list.61.weight  |         784          |\n",
      "|  module_list.61.bias   |          1           |\n",
      "| module_list.62.weight  |         784          |\n",
      "|  module_list.62.bias   |          1           |\n",
      "| module_list.63.weight  |         784          |\n",
      "|  module_list.63.bias   |          1           |\n",
      "| module_list.64.weight  |         784          |\n",
      "|  module_list.64.bias   |          1           |\n",
      "| module_list.65.weight  |         784          |\n",
      "|  module_list.65.bias   |          1           |\n",
      "| module_list.66.weight  |         784          |\n",
      "|  module_list.66.bias   |          1           |\n",
      "| module_list.67.weight  |         784          |\n",
      "|  module_list.67.bias   |          1           |\n",
      "| module_list.68.weight  |         784          |\n",
      "|  module_list.68.bias   |          1           |\n",
      "| module_list.69.weight  |         784          |\n",
      "|  module_list.69.bias   |          1           |\n",
      "| module_list.70.weight  |         784          |\n",
      "|  module_list.70.bias   |          1           |\n",
      "| module_list.71.weight  |         784          |\n",
      "|  module_list.71.bias   |          1           |\n",
      "| module_list.72.weight  |         784          |\n",
      "|  module_list.72.bias   |          1           |\n",
      "| module_list.73.weight  |         784          |\n",
      "|  module_list.73.bias   |          1           |\n",
      "| module_list.74.weight  |         784          |\n",
      "|  module_list.74.bias   |          1           |\n",
      "| module_list.75.weight  |         784          |\n",
      "|  module_list.75.bias   |          1           |\n",
      "| module_list.76.weight  |         784          |\n",
      "|  module_list.76.bias   |          1           |\n",
      "| module_list.77.weight  |         784          |\n",
      "|  module_list.77.bias   |          1           |\n",
      "| module_list.78.weight  |         784          |\n",
      "|  module_list.78.bias   |          1           |\n",
      "| module_list.79.weight  |         784          |\n",
      "|  module_list.79.bias   |          1           |\n",
      "| module_list.80.weight  |         784          |\n",
      "|  module_list.80.bias   |          1           |\n",
      "| module_list.81.weight  |         784          |\n",
      "|  module_list.81.bias   |          1           |\n",
      "| module_list.82.weight  |         784          |\n",
      "|  module_list.82.bias   |          1           |\n",
      "| module_list.83.weight  |         784          |\n",
      "|  module_list.83.bias   |          1           |\n",
      "| module_list.84.weight  |         784          |\n",
      "|  module_list.84.bias   |          1           |\n",
      "| module_list.85.weight  |         784          |\n",
      "|  module_list.85.bias   |          1           |\n",
      "| module_list.86.weight  |         784          |\n",
      "|  module_list.86.bias   |          1           |\n",
      "| module_list.87.weight  |         784          |\n",
      "|  module_list.87.bias   |          1           |\n",
      "| module_list.88.weight  |         784          |\n",
      "|  module_list.88.bias   |          1           |\n",
      "| module_list.89.weight  |         784          |\n",
      "|  module_list.89.bias   |          1           |\n",
      "| module_list.90.weight  |         784          |\n",
      "|  module_list.90.bias   |          1           |\n",
      "| module_list.91.weight  |         784          |\n",
      "|  module_list.91.bias   |          1           |\n",
      "| module_list.92.weight  |         784          |\n",
      "|  module_list.92.bias   |          1           |\n",
      "| module_list.93.weight  |         784          |\n",
      "|  module_list.93.bias   |          1           |\n",
      "| module_list.94.weight  |         784          |\n",
      "|  module_list.94.bias   |          1           |\n",
      "| module_list.95.weight  |         784          |\n",
      "|  module_list.95.bias   |          1           |\n",
      "| module_list.96.weight  |         784          |\n",
      "|  module_list.96.bias   |          1           |\n",
      "| module_list.97.weight  |         784          |\n",
      "|  module_list.97.bias   |          1           |\n",
      "| module_list.98.weight  |         784          |\n",
      "|  module_list.98.bias   |          1           |\n",
      "| module_list.99.weight  |         784          |\n",
      "|  module_list.99.bias   |          1           |\n",
      "| module_list.100.weight |         784          |\n",
      "|  module_list.100.bias  |          1           |\n",
      "| module_list.101.weight |         784          |\n",
      "|  module_list.101.bias  |          1           |\n",
      "| module_list.102.weight |         784          |\n",
      "|  module_list.102.bias  |          1           |\n",
      "| module_list.103.weight |         784          |\n",
      "|  module_list.103.bias  |          1           |\n",
      "| module_list.104.weight |         784          |\n",
      "|  module_list.104.bias  |          1           |\n",
      "| module_list.105.weight |         784          |\n",
      "|  module_list.105.bias  |          1           |\n",
      "| module_list.106.weight |         784          |\n",
      "|  module_list.106.bias  |          1           |\n",
      "| module_list.107.weight |         784          |\n",
      "|  module_list.107.bias  |          1           |\n",
      "| module_list.108.weight |         784          |\n",
      "|  module_list.108.bias  |          1           |\n",
      "| module_list.109.weight |         784          |\n",
      "|  module_list.109.bias  |          1           |\n",
      "| module_list.110.weight |         784          |\n",
      "|  module_list.110.bias  |          1           |\n",
      "| module_list.111.weight |         784          |\n",
      "|  module_list.111.bias  |          1           |\n",
      "| module_list.112.weight |         784          |\n",
      "|  module_list.112.bias  |          1           |\n",
      "| module_list.113.weight |         784          |\n",
      "|  module_list.113.bias  |          1           |\n",
      "| module_list.114.weight |         784          |\n",
      "|  module_list.114.bias  |          1           |\n",
      "| module_list.115.weight |         784          |\n",
      "|  module_list.115.bias  |          1           |\n",
      "| module_list.116.weight |         784          |\n",
      "|  module_list.116.bias  |          1           |\n",
      "| module_list.117.weight |         784          |\n",
      "|  module_list.117.bias  |          1           |\n",
      "| module_list.118.weight |         784          |\n",
      "|  module_list.118.bias  |          1           |\n",
      "| module_list.119.weight |         784          |\n",
      "|  module_list.119.bias  |          1           |\n",
      "| module_list.120.weight |         784          |\n",
      "|  module_list.120.bias  |          1           |\n",
      "| module_list.121.weight |         784          |\n",
      "|  module_list.121.bias  |          1           |\n",
      "| module_list.122.weight |         784          |\n",
      "|  module_list.122.bias  |          1           |\n",
      "| module_list.123.weight |         784          |\n",
      "|  module_list.123.bias  |          1           |\n",
      "| module_list.124.weight |         784          |\n",
      "|  module_list.124.bias  |          1           |\n",
      "| module_list.125.weight |         784          |\n",
      "|  module_list.125.bias  |          1           |\n",
      "| module_list.126.weight |         784          |\n",
      "|  module_list.126.bias  |          1           |\n",
      "| module_list.127.weight |         784          |\n",
      "|  module_list.127.bias  |          1           |\n",
      "| module_list.128.weight |         784          |\n",
      "|  module_list.128.bias  |          1           |\n",
      "| module_list.129.weight |         784          |\n",
      "|  module_list.129.bias  |          1           |\n",
      "| module_list.130.weight |         784          |\n",
      "|  module_list.130.bias  |          1           |\n",
      "| module_list.131.weight |         784          |\n",
      "|  module_list.131.bias  |          1           |\n",
      "| module_list.132.weight |         784          |\n",
      "|  module_list.132.bias  |          1           |\n",
      "| module_list.133.weight |         784          |\n",
      "|  module_list.133.bias  |          1           |\n",
      "| module_list.134.weight |         784          |\n",
      "|  module_list.134.bias  |          1           |\n",
      "| module_list.135.weight |         784          |\n",
      "|  module_list.135.bias  |          1           |\n",
      "| module_list.136.weight |         784          |\n",
      "|  module_list.136.bias  |          1           |\n",
      "| module_list.137.weight |         784          |\n",
      "|  module_list.137.bias  |          1           |\n",
      "| module_list.138.weight |         784          |\n",
      "|  module_list.138.bias  |          1           |\n",
      "| module_list.139.weight |         784          |\n",
      "|  module_list.139.bias  |          1           |\n",
      "| module_list.140.weight |         784          |\n",
      "|  module_list.140.bias  |          1           |\n",
      "| module_list.141.weight |         784          |\n",
      "|  module_list.141.bias  |          1           |\n",
      "| module_list.142.weight |         784          |\n",
      "|  module_list.142.bias  |          1           |\n",
      "| module_list.143.weight |         784          |\n",
      "|  module_list.143.bias  |          1           |\n",
      "| module_list.144.weight |         784          |\n",
      "|  module_list.144.bias  |          1           |\n",
      "| module_list.145.weight |         784          |\n",
      "|  module_list.145.bias  |          1           |\n",
      "| module_list.146.weight |         784          |\n",
      "|  module_list.146.bias  |          1           |\n",
      "| module_list.147.weight |         784          |\n",
      "|  module_list.147.bias  |          1           |\n",
      "| module_list.148.weight |         784          |\n",
      "|  module_list.148.bias  |          1           |\n",
      "| module_list.149.weight |         784          |\n",
      "|  module_list.149.bias  |          1           |\n",
      "| module_list.150.weight |         784          |\n",
      "|  module_list.150.bias  |          1           |\n",
      "| module_list.151.weight |         784          |\n",
      "|  module_list.151.bias  |          1           |\n",
      "| module_list.152.weight |         784          |\n",
      "|  module_list.152.bias  |          1           |\n",
      "| module_list.153.weight |         784          |\n",
      "|  module_list.153.bias  |          1           |\n",
      "| module_list.154.weight |         784          |\n",
      "|  module_list.154.bias  |          1           |\n",
      "| module_list.155.weight |         784          |\n",
      "|  module_list.155.bias  |          1           |\n",
      "| module_list.156.weight |         784          |\n",
      "|  module_list.156.bias  |          1           |\n",
      "| module_list.157.weight |         784          |\n",
      "|  module_list.157.bias  |          1           |\n",
      "| module_list.158.weight |         784          |\n",
      "|  module_list.158.bias  |          1           |\n",
      "| module_list.159.weight |         784          |\n",
      "|  module_list.159.bias  |          1           |\n",
      "| module_list.160.weight |         784          |\n",
      "|  module_list.160.bias  |          1           |\n",
      "| module_list.161.weight |         784          |\n",
      "|  module_list.161.bias  |          1           |\n",
      "| module_list.162.weight |         784          |\n",
      "|  module_list.162.bias  |          1           |\n",
      "| module_list.163.weight |         784          |\n",
      "|  module_list.163.bias  |          1           |\n",
      "| module_list.164.weight |         784          |\n",
      "|  module_list.164.bias  |          1           |\n",
      "| module_list.165.weight |         784          |\n",
      "|  module_list.165.bias  |          1           |\n",
      "| module_list.166.weight |         784          |\n",
      "|  module_list.166.bias  |          1           |\n",
      "| module_list.167.weight |         784          |\n",
      "|  module_list.167.bias  |          1           |\n",
      "| module_list.168.weight |         784          |\n",
      "|  module_list.168.bias  |          1           |\n",
      "| module_list.169.weight |         784          |\n",
      "|  module_list.169.bias  |          1           |\n",
      "| module_list.170.weight |         784          |\n",
      "|  module_list.170.bias  |          1           |\n",
      "| module_list.171.weight |         784          |\n",
      "|  module_list.171.bias  |          1           |\n",
      "| module_list.172.weight |         784          |\n",
      "|  module_list.172.bias  |          1           |\n",
      "| module_list.173.weight |         784          |\n",
      "|  module_list.173.bias  |          1           |\n",
      "| module_list.174.weight |         784          |\n",
      "|  module_list.174.bias  |          1           |\n",
      "| module_list.175.weight |         784          |\n",
      "|  module_list.175.bias  |          1           |\n",
      "| module_list.176.weight |         784          |\n",
      "|  module_list.176.bias  |          1           |\n",
      "| module_list.177.weight |         784          |\n",
      "|  module_list.177.bias  |          1           |\n",
      "| module_list.178.weight |         784          |\n",
      "|  module_list.178.bias  |          1           |\n",
      "| module_list.179.weight |         784          |\n",
      "|  module_list.179.bias  |          1           |\n",
      "| module_list.180.weight |         784          |\n",
      "|  module_list.180.bias  |          1           |\n",
      "| module_list.181.weight |         784          |\n",
      "|  module_list.181.bias  |          1           |\n",
      "| module_list.182.weight |         784          |\n",
      "|  module_list.182.bias  |          1           |\n",
      "| module_list.183.weight |         784          |\n",
      "|  module_list.183.bias  |          1           |\n",
      "| module_list.184.weight |         784          |\n",
      "|  module_list.184.bias  |          1           |\n",
      "| module_list.185.weight |         784          |\n",
      "|  module_list.185.bias  |          1           |\n",
      "| module_list.186.weight |         784          |\n",
      "|  module_list.186.bias  |          1           |\n",
      "| module_list.187.weight |         784          |\n",
      "|  module_list.187.bias  |          1           |\n",
      "| module_list.188.weight |         784          |\n",
      "|  module_list.188.bias  |          1           |\n",
      "| module_list.189.weight |         784          |\n",
      "|  module_list.189.bias  |          1           |\n",
      "| module_list.190.weight |         784          |\n",
      "|  module_list.190.bias  |          1           |\n",
      "| module_list.191.weight |         784          |\n",
      "|  module_list.191.bias  |          1           |\n",
      "| module_list.192.weight |         784          |\n",
      "|  module_list.192.bias  |          1           |\n",
      "| module_list.193.weight |         784          |\n",
      "|  module_list.193.bias  |          1           |\n",
      "| module_list.194.weight |         784          |\n",
      "|  module_list.194.bias  |          1           |\n",
      "| module_list.195.weight |         784          |\n",
      "|  module_list.195.bias  |          1           |\n",
      "| module_list.196.weight |         784          |\n",
      "|  module_list.196.bias  |          1           |\n",
      "| module_list.197.weight |         784          |\n",
      "|  module_list.197.bias  |          1           |\n",
      "| module_list.198.weight |         784          |\n",
      "|  module_list.198.bias  |          1           |\n",
      "| module_list.199.weight |         784          |\n",
      "|  module_list.199.bias  |          1           |\n",
      "| module_list.200.weight |         784          |\n",
      "|  module_list.200.bias  |          1           |\n",
      "| module_list.201.weight |         784          |\n",
      "|  module_list.201.bias  |          1           |\n",
      "| module_list.202.weight |         784          |\n",
      "|  module_list.202.bias  |          1           |\n",
      "| module_list.203.weight |         784          |\n",
      "|  module_list.203.bias  |          1           |\n",
      "| module_list.204.weight |         784          |\n",
      "|  module_list.204.bias  |          1           |\n",
      "| module_list.205.weight |         784          |\n",
      "|  module_list.205.bias  |          1           |\n",
      "| module_list.206.weight |         784          |\n",
      "|  module_list.206.bias  |          1           |\n",
      "| module_list.207.weight |         784          |\n",
      "|  module_list.207.bias  |          1           |\n",
      "| module_list.208.weight |         784          |\n",
      "|  module_list.208.bias  |          1           |\n",
      "| module_list.209.weight |         784          |\n",
      "|  module_list.209.bias  |          1           |\n",
      "| module_list.210.weight |         784          |\n",
      "|  module_list.210.bias  |          1           |\n",
      "| module_list.211.weight |         784          |\n",
      "|  module_list.211.bias  |          1           |\n",
      "| module_list.212.weight |         784          |\n",
      "|  module_list.212.bias  |          1           |\n",
      "| module_list.213.weight |         784          |\n",
      "|  module_list.213.bias  |          1           |\n",
      "| module_list.214.weight |         784          |\n",
      "|  module_list.214.bias  |          1           |\n",
      "| module_list.215.weight |         784          |\n",
      "|  module_list.215.bias  |          1           |\n",
      "| module_list.216.weight |         784          |\n",
      "|  module_list.216.bias  |          1           |\n",
      "| module_list.217.weight |         784          |\n",
      "|  module_list.217.bias  |          1           |\n",
      "| module_list.218.weight |         784          |\n",
      "|  module_list.218.bias  |          1           |\n",
      "| module_list.219.weight |         784          |\n",
      "|  module_list.219.bias  |          1           |\n",
      "| module_list.220.weight |         784          |\n",
      "|  module_list.220.bias  |          1           |\n",
      "| module_list.221.weight |         784          |\n",
      "|  module_list.221.bias  |          1           |\n",
      "| module_list.222.weight |         784          |\n",
      "|  module_list.222.bias  |          1           |\n",
      "| module_list.223.weight |         784          |\n",
      "|  module_list.223.bias  |          1           |\n",
      "| module_list.224.weight |         784          |\n",
      "|  module_list.224.bias  |          1           |\n",
      "| module_list.225.weight |         784          |\n",
      "|  module_list.225.bias  |          1           |\n",
      "| module_list.226.weight |         784          |\n",
      "|  module_list.226.bias  |          1           |\n",
      "| module_list.227.weight |         784          |\n",
      "|  module_list.227.bias  |          1           |\n",
      "| module_list.228.weight |         784          |\n",
      "|  module_list.228.bias  |          1           |\n",
      "| module_list.229.weight |         784          |\n",
      "|  module_list.229.bias  |          1           |\n",
      "| module_list.230.weight |         784          |\n",
      "|  module_list.230.bias  |          1           |\n",
      "| module_list.231.weight |         784          |\n",
      "|  module_list.231.bias  |          1           |\n",
      "| module_list.232.weight |         784          |\n",
      "|  module_list.232.bias  |          1           |\n",
      "| module_list.233.weight |         784          |\n",
      "|  module_list.233.bias  |          1           |\n",
      "| module_list.234.weight |         784          |\n",
      "|  module_list.234.bias  |          1           |\n",
      "| module_list.235.weight |         784          |\n",
      "|  module_list.235.bias  |          1           |\n",
      "| module_list.236.weight |         784          |\n",
      "|  module_list.236.bias  |          1           |\n",
      "| module_list.237.weight |         784          |\n",
      "|  module_list.237.bias  |          1           |\n",
      "| module_list.238.weight |         784          |\n",
      "|  module_list.238.bias  |          1           |\n",
      "| module_list.239.weight |         784          |\n",
      "|  module_list.239.bias  |          1           |\n",
      "| module_list.240.weight |         784          |\n",
      "|  module_list.240.bias  |          1           |\n",
      "| module_list.241.weight |         784          |\n",
      "|  module_list.241.bias  |          1           |\n",
      "| module_list.242.weight |         784          |\n",
      "|  module_list.242.bias  |          1           |\n",
      "| module_list.243.weight |         784          |\n",
      "|  module_list.243.bias  |          1           |\n",
      "| module_list.244.weight |         784          |\n",
      "|  module_list.244.bias  |          1           |\n",
      "| module_list.245.weight |         784          |\n",
      "|  module_list.245.bias  |          1           |\n",
      "| module_list.246.weight |         784          |\n",
      "|  module_list.246.bias  |          1           |\n",
      "| module_list.247.weight |         784          |\n",
      "|  module_list.247.bias  |          1           |\n",
      "| module_list.248.weight |         784          |\n",
      "|  module_list.248.bias  |          1           |\n",
      "| module_list.249.weight |         784          |\n",
      "|  module_list.249.bias  |          1           |\n",
      "| module_list.250.weight |         784          |\n",
      "|  module_list.250.bias  |          1           |\n",
      "| module_list.251.weight |         784          |\n",
      "|  module_list.251.bias  |          1           |\n",
      "| module_list.252.weight |         784          |\n",
      "|  module_list.252.bias  |          1           |\n",
      "| module_list.253.weight |         784          |\n",
      "|  module_list.253.bias  |          1           |\n",
      "| module_list.254.weight |         784          |\n",
      "|  module_list.254.bias  |          1           |\n",
      "|      param_list.0      |          10          |\n",
      "|      param_list.1      |          10          |\n",
      "|      param_list.2      |          10          |\n",
      "|      param_list.3      |          10          |\n",
      "|      param_list.4      |          10          |\n",
      "|      param_list.5      |          10          |\n",
      "|      param_list.6      |          10          |\n",
      "|      param_list.7      |          10          |\n",
      "|      param_list.8      |          10          |\n",
      "|      param_list.9      |          10          |\n",
      "|     param_list.10      |          10          |\n",
      "|     param_list.11      |          10          |\n",
      "|     param_list.12      |          10          |\n",
      "|     param_list.13      |          10          |\n",
      "|     param_list.14      |          10          |\n",
      "|     param_list.15      |          10          |\n",
      "|     param_list.16      |          10          |\n",
      "|     param_list.17      |          10          |\n",
      "|     param_list.18      |          10          |\n",
      "|     param_list.19      |          10          |\n",
      "|     param_list.20      |          10          |\n",
      "|     param_list.21      |          10          |\n",
      "|     param_list.22      |          10          |\n",
      "|     param_list.23      |          10          |\n",
      "|     param_list.24      |          10          |\n",
      "|     param_list.25      |          10          |\n",
      "|     param_list.26      |          10          |\n",
      "|     param_list.27      |          10          |\n",
      "|     param_list.28      |          10          |\n",
      "|     param_list.29      |          10          |\n",
      "|     param_list.30      |          10          |\n",
      "|     param_list.31      |          10          |\n",
      "|     param_list.32      |          10          |\n",
      "|     param_list.33      |          10          |\n",
      "|     param_list.34      |          10          |\n",
      "|     param_list.35      |          10          |\n",
      "|     param_list.36      |          10          |\n",
      "|     param_list.37      |          10          |\n",
      "|     param_list.38      |          10          |\n",
      "|     param_list.39      |          10          |\n",
      "|     param_list.40      |          10          |\n",
      "|     param_list.41      |          10          |\n",
      "|     param_list.42      |          10          |\n",
      "|     param_list.43      |          10          |\n",
      "|     param_list.44      |          10          |\n",
      "|     param_list.45      |          10          |\n",
      "|     param_list.46      |          10          |\n",
      "|     param_list.47      |          10          |\n",
      "|     param_list.48      |          10          |\n",
      "|     param_list.49      |          10          |\n",
      "|     param_list.50      |          10          |\n",
      "|     param_list.51      |          10          |\n",
      "|     param_list.52      |          10          |\n",
      "|     param_list.53      |          10          |\n",
      "|     param_list.54      |          10          |\n",
      "|     param_list.55      |          10          |\n",
      "|     param_list.56      |          10          |\n",
      "|     param_list.57      |          10          |\n",
      "|     param_list.58      |          10          |\n",
      "|     param_list.59      |          10          |\n",
      "|     param_list.60      |          10          |\n",
      "|     param_list.61      |          10          |\n",
      "|     param_list.62      |          10          |\n",
      "|     param_list.63      |          10          |\n",
      "|     param_list.64      |          10          |\n",
      "|     param_list.65      |          10          |\n",
      "|     param_list.66      |          10          |\n",
      "|     param_list.67      |          10          |\n",
      "|     param_list.68      |          10          |\n",
      "|     param_list.69      |          10          |\n",
      "|     param_list.70      |          10          |\n",
      "|     param_list.71      |          10          |\n",
      "|     param_list.72      |          10          |\n",
      "|     param_list.73      |          10          |\n",
      "|     param_list.74      |          10          |\n",
      "|     param_list.75      |          10          |\n",
      "|     param_list.76      |          10          |\n",
      "|     param_list.77      |          10          |\n",
      "|     param_list.78      |          10          |\n",
      "|     param_list.79      |          10          |\n",
      "|     param_list.80      |          10          |\n",
      "|     param_list.81      |          10          |\n",
      "|     param_list.82      |          10          |\n",
      "|     param_list.83      |          10          |\n",
      "|     param_list.84      |          10          |\n",
      "|     param_list.85      |          10          |\n",
      "|     param_list.86      |          10          |\n",
      "|     param_list.87      |          10          |\n",
      "|     param_list.88      |          10          |\n",
      "|     param_list.89      |          10          |\n",
      "|     param_list.90      |          10          |\n",
      "|     param_list.91      |          10          |\n",
      "|     param_list.92      |          10          |\n",
      "|     param_list.93      |          10          |\n",
      "|     param_list.94      |          10          |\n",
      "|     param_list.95      |          10          |\n",
      "|     param_list.96      |          10          |\n",
      "|     param_list.97      |          10          |\n",
      "|     param_list.98      |          10          |\n",
      "|     param_list.99      |          10          |\n",
      "|     param_list.100     |          10          |\n",
      "|     param_list.101     |          10          |\n",
      "|     param_list.102     |          10          |\n",
      "|     param_list.103     |          10          |\n",
      "|     param_list.104     |          10          |\n",
      "|     param_list.105     |          10          |\n",
      "|     param_list.106     |          10          |\n",
      "|     param_list.107     |          10          |\n",
      "|     param_list.108     |          10          |\n",
      "|     param_list.109     |          10          |\n",
      "|     param_list.110     |          10          |\n",
      "|     param_list.111     |          10          |\n",
      "|     param_list.112     |          10          |\n",
      "|     param_list.113     |          10          |\n",
      "|     param_list.114     |          10          |\n",
      "|     param_list.115     |          10          |\n",
      "|     param_list.116     |          10          |\n",
      "|     param_list.117     |          10          |\n",
      "|     param_list.118     |          10          |\n",
      "|     param_list.119     |          10          |\n",
      "|     param_list.120     |          10          |\n",
      "|     param_list.121     |          10          |\n",
      "|     param_list.122     |          10          |\n",
      "|     param_list.123     |          10          |\n",
      "|     param_list.124     |          10          |\n",
      "|     param_list.125     |          10          |\n",
      "|     param_list.126     |          10          |\n",
      "|     param_list.127     |          10          |\n",
      "|     param_list.128     |          10          |\n",
      "|     param_list.129     |          10          |\n",
      "|     param_list.130     |          10          |\n",
      "|     param_list.131     |          10          |\n",
      "|     param_list.132     |          10          |\n",
      "|     param_list.133     |          10          |\n",
      "|     param_list.134     |          10          |\n",
      "|     param_list.135     |          10          |\n",
      "|     param_list.136     |          10          |\n",
      "|     param_list.137     |          10          |\n",
      "|     param_list.138     |          10          |\n",
      "|     param_list.139     |          10          |\n",
      "|     param_list.140     |          10          |\n",
      "|     param_list.141     |          10          |\n",
      "|     param_list.142     |          10          |\n",
      "|     param_list.143     |          10          |\n",
      "|     param_list.144     |          10          |\n",
      "|     param_list.145     |          10          |\n",
      "|     param_list.146     |          10          |\n",
      "|     param_list.147     |          10          |\n",
      "|     param_list.148     |          10          |\n",
      "|     param_list.149     |          10          |\n",
      "|     param_list.150     |          10          |\n",
      "|     param_list.151     |          10          |\n",
      "|     param_list.152     |          10          |\n",
      "|     param_list.153     |          10          |\n",
      "|     param_list.154     |          10          |\n",
      "|     param_list.155     |          10          |\n",
      "|     param_list.156     |          10          |\n",
      "|     param_list.157     |          10          |\n",
      "|     param_list.158     |          10          |\n",
      "|     param_list.159     |          10          |\n",
      "|     param_list.160     |          10          |\n",
      "|     param_list.161     |          10          |\n",
      "|     param_list.162     |          10          |\n",
      "|     param_list.163     |          10          |\n",
      "|     param_list.164     |          10          |\n",
      "|     param_list.165     |          10          |\n",
      "|     param_list.166     |          10          |\n",
      "|     param_list.167     |          10          |\n",
      "|     param_list.168     |          10          |\n",
      "|     param_list.169     |          10          |\n",
      "|     param_list.170     |          10          |\n",
      "|     param_list.171     |          10          |\n",
      "|     param_list.172     |          10          |\n",
      "|     param_list.173     |          10          |\n",
      "|     param_list.174     |          10          |\n",
      "|     param_list.175     |          10          |\n",
      "|     param_list.176     |          10          |\n",
      "|     param_list.177     |          10          |\n",
      "|     param_list.178     |          10          |\n",
      "|     param_list.179     |          10          |\n",
      "|     param_list.180     |          10          |\n",
      "|     param_list.181     |          10          |\n",
      "|     param_list.182     |          10          |\n",
      "|     param_list.183     |          10          |\n",
      "|     param_list.184     |          10          |\n",
      "|     param_list.185     |          10          |\n",
      "|     param_list.186     |          10          |\n",
      "|     param_list.187     |          10          |\n",
      "|     param_list.188     |          10          |\n",
      "|     param_list.189     |          10          |\n",
      "|     param_list.190     |          10          |\n",
      "|     param_list.191     |          10          |\n",
      "|     param_list.192     |          10          |\n",
      "|     param_list.193     |          10          |\n",
      "|     param_list.194     |          10          |\n",
      "|     param_list.195     |          10          |\n",
      "|     param_list.196     |          10          |\n",
      "|     param_list.197     |          10          |\n",
      "|     param_list.198     |          10          |\n",
      "|     param_list.199     |          10          |\n",
      "|     param_list.200     |          10          |\n",
      "|     param_list.201     |          10          |\n",
      "|     param_list.202     |          10          |\n",
      "|     param_list.203     |          10          |\n",
      "|     param_list.204     |          10          |\n",
      "|     param_list.205     |          10          |\n",
      "|     param_list.206     |          10          |\n",
      "|     param_list.207     |          10          |\n",
      "|     param_list.208     |          10          |\n",
      "|     param_list.209     |          10          |\n",
      "|     param_list.210     |          10          |\n",
      "|     param_list.211     |          10          |\n",
      "|     param_list.212     |          10          |\n",
      "|     param_list.213     |          10          |\n",
      "|     param_list.214     |          10          |\n",
      "|     param_list.215     |          10          |\n",
      "|     param_list.216     |          10          |\n",
      "|     param_list.217     |          10          |\n",
      "|     param_list.218     |          10          |\n",
      "|     param_list.219     |          10          |\n",
      "|     param_list.220     |          10          |\n",
      "|     param_list.221     |          10          |\n",
      "|     param_list.222     |          10          |\n",
      "|     param_list.223     |          10          |\n",
      "|     param_list.224     |          10          |\n",
      "|     param_list.225     |          10          |\n",
      "|     param_list.226     |          10          |\n",
      "|     param_list.227     |          10          |\n",
      "|     param_list.228     |          10          |\n",
      "|     param_list.229     |          10          |\n",
      "|     param_list.230     |          10          |\n",
      "|     param_list.231     |          10          |\n",
      "|     param_list.232     |          10          |\n",
      "|     param_list.233     |          10          |\n",
      "|     param_list.234     |          10          |\n",
      "|     param_list.235     |          10          |\n",
      "|     param_list.236     |          10          |\n",
      "|     param_list.237     |          10          |\n",
      "|     param_list.238     |          10          |\n",
      "|     param_list.239     |          10          |\n",
      "|     param_list.240     |          10          |\n",
      "|     param_list.241     |          10          |\n",
      "|     param_list.242     |          10          |\n",
      "|     param_list.243     |          10          |\n",
      "|     param_list.244     |          10          |\n",
      "|     param_list.245     |          10          |\n",
      "|     param_list.246     |          10          |\n",
      "|     param_list.247     |          10          |\n",
      "|     param_list.248     |          10          |\n",
      "|     param_list.249     |          10          |\n",
      "|     param_list.250     |          10          |\n",
      "|     param_list.251     |          10          |\n",
      "|     param_list.252     |          10          |\n",
      "|     param_list.253     |          10          |\n",
      "|     param_list.254     |          10          |\n",
      "|     param_list.255     |          10          |\n",
      "|         Total          |        202735        |\n",
      "+------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "# Initialize table\n",
    "table = PrettyTable([\"Layer Name\", \"Number of Parameters\"])\n",
    "\n",
    "total_params = 0\n",
    "\n",
    "for name, parameter in tre.named_parameters():\n",
    "    if not parameter.requires_grad: continue\n",
    "    param = parameter.numel()\n",
    "    table.add_row([name, param])\n",
    "    total_params += param\n",
    "\n",
    "table.add_row([\"Total\", total_params])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e23c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
